[{"title":"浅谈目标检测——RCNN系列","date":"2019-07-05T13:44:45.000Z","path":"2019/07/05/浅谈目标检测——RCNN系列/","text":"目标检测概述对于计算机视觉领域里有三类比较经典的视觉任务：即图像分类，图像检测和图像分割。图像分类任务里面，我们假设图像里只有一个主体目标，并关注如何识别该目标的类别。然而，大多数情况下，我们不仅想知道图像中目标的类别，还想知道目标在图像中的位置，我们将这类任务称之为目标检测(object detection)，通俗来讲目标检测定义了一个classification和localization两个子任务的复合任务。当前主流的目标检测算法主要有以one-stage为代表的yolo和ssd，以及two-stage为代表的的RCNN系列。以下对two-stage算法RCNN系列进行介绍说明。 RCNN时间回到2014年，那是深度学习如火如荼发展的第三年，当时Ross Girshick提出了一种使用卷积神经网络来完成目标检测的的算法RCNN,下面简要说明RCNN的工作原理。简单来说，RCNN工作流程分3步： 输入一张图片，使用selective search方法在图片上生成~2K个待检测区域。 在这~2K个待检测区域，每一个待检测区域过一遍CNN网络进行特征提取，将提取到的特征存盘 对这些特征训练一个SVM进行目标分类，得到目标类别，通过Bounding Box Regression调整目标框的大小具体来说，在第一步中，作者采用一个2012年提出的方法叫selective search,这个方法大概意思是采用传统的图像处理方式，将属于同一个目标的若干块从图像上crop出来作为目标检测的候选区域。在第二步特征提取的时候，作者借用了当时AlexNet成果，在imagenet上预训练好的参数去掉最后面的全连接层仅用于特征提取。第三步对目标识别时，作者单独训练一个SVM用于目标的分类任务，使用Bounding Box Regression完成目标框的回归任务。 关于RCNN的贡献，我们归结为以下两点： 首次在目标检测任务中使用卷积神经网络进行特征提取 使用了bounding box regression进行目标框的修正 在当时RCNN的横空出世刷新了以往目标检测方案的精度，然而其缺点也是致命的：1）首先测试需要耗时间近49s，~2K个region proposal依次通过CNN网络提特征需要占用47s，selective search做框推荐花费2s多2）庞大的存储开销，在上述第二步中，~2K个候选区依次前向通过CNN得到的特征需要存储到硬盘用于后面SVM分类器的训练3）CNN，SVM，bounding box regression是分别进行训练的 Fast-RCNN针对RCNN的弊端，作者第二年（2015年）提出了一种改进方法Fast-RCNN,作者认为在RCNN网络中，selective search推荐出的候选区很多都是重叠的，因此没必要将生成的2000个候选区依次通过CNN提取特征，而是将原图输入到CNN完成一次特征提取，在feature map上做region proposal。除此之外，在Fast-RCNN中，目标的分类和目标框的修正统一采用了全连接层FC完成。总结Fast-RCNN的主要贡献：1）取代RCNN的串行方式提取特征，直接仅一次对原图通过CNN网络进行特征提取2）首次使用RoI polling3）除了selective search其他部分都可以在一起训练。 Fast_RCNN相对RCNN不论在精度还是速度上都取得了令人瞩目的进步，特别是预测速度方面从RCNN的49秒降到了2.3秒，然而这对于工业界落地依旧存在问题，而这个耗时的主要根源是selective search，如何进一步改良这个问题呢？次年（2016年）何凯明、任少卿和RCNN的原作Ross Girshick做了新地改进尝试，提出了更快的RCNN，即Faster-RCNN。 Faster-RCNN实验数据表明，制约Fast-RCNN预测速度的是selective search，2016年Faster-RCNN在Fast-RCNN基础之上做了新的尝试，通过一个Region Proposal Network(RPN)代替selective search方法来生成待检测区，如此一来，在生成RoI的时候从2s降低到了约10ms，使得Faster-RCNN的预测速度降低到了0.2s，基本达到了“实时效果”。从上图我们可以看到，Faster-RCNN使用共享的卷积层为原图提feature，然后将feature送入到RPN网络，RPN网络生成一些待检测区（RoI），并对这些区域进行目标和背景的分类，以及第一次框修正。之后就是Fast-RCNN的的结构了，值得注意的是Faster-RCNN真正意义上实现了end-to-end的训练。要理解Faster-RCNN，关键要知道RPN的工作原理： RPN网络首先原图（假设是800x600），经过CNN网络之后16倍降采样后得到的feature map大小为50x38，RPN在这个feature map上为每一个点生成预先设定好宽高比和大小的anchor，这9种初始anchor包含三种面积（128x128，256x256，512x512），同一种面积宽高比又有（1:1，1:2，2:1）三种，因此RPN生成的初始anchor总共是17100（原文是约20000个，后文统一说20000个）。对于生成的约20000个anchor，RPN要做两件事：①anchor是前景还是背景，即有没有覆盖目标，②为属于前景的anchor进行一次框修正。对于问题①，RPN的做法是，排除掉了超越图像边界的anchor，使用softmaxLoss进行直接训练。对于问题②，作者使用smothL1进行训练。那么RPN结构是什么样呢？RPN实际上是一个树状结构，树干是featuremap 通过kernelsize=3x3,stride=1,pading=1卷积核完成一次卷积运算（大小不变，输出通道是512维），后分叉为两个1x1的卷积，左边的一支解决了anchor是前景还是背景的问题，右边的一支是对包含前景的anchor做了框修正。可以看出做前景背景分类的卷积输出18个值，为什么是18个值呢？因为feature map上每一个点对应9个anchor，每个anchor都会预测一个前景分数+一个背景分数，因此9x2=18个；而对于框回归的卷积输出了36个值，，因为每个anchor对应4个修正坐标，因此9x4=36个。 RPN的训练话题继续回到RPN训练上，对于一个anchor是前景还是背景，论文作者给出的定义是：如果一个anchor和GT的IOU大于0.7，那么这个anchor就算是包含前景（目标）；如果和GT的IOU小于0.3，则定义为背景，作者在训练RPN的时候只用到了以上两类anchor，对于和GT的IOU介于0.3~0.7的anchor没有使用，值得注意的是，在训练前景背景分类的时候，作者采用的方式是随机抽取128个前景anchor和128个背景anchor。RPN中框修正的训练，作者定义GT的坐标为$GT=[G_x,G_y,G_w,G_h]$，anchor的坐标为$A=[A_x,A_y,A_w,A_h]$,训练框修正，其实就是寻找一种变换F,使得$F(A_x,A_y,A_w,A_h)=(G_x^,G_y^,G_w^,G_h^)$，其中$(G_x^,G_y^,G_w^,G_h^)\\approx(G_x,G_y,G_w,G_h)$ 即先做平移： \\begin{cases} G_x^* = A_w · d_x(A)+A_x \\\\ G_y^* = A_h · d_y(A)+A_y \\end{cases}再做缩放 \\begin{cases} G_w^* = A_w · exp(d_w(A)) \\\\ G_h^* = A_h · exp(d_w(A)) \\end{cases}即我们要训练参数d_*(A),其中*代表的是x,y,w,h四个下标。如何训练得到这四个参数呢？作者采用SmoothL1进行训练，框回归损失为：$L_{loc}(t^u,\\nu)=\\sum_{i\\in\\{x,y,w,h\\}} smooth_{L1}(t_i^u-\\nu_i)$ 其中 smooth_{L1}= \\begin{cases} 0.5x^2, & \\text{if |x|","tags":[{"name":"目标检测 RCNN Fast-RCNN Faster-RCNN","slug":"目标检测-RCNN-Fast-RCNN-Faster-RCNN","permalink":"http://yoursite.com/tags/目标检测-RCNN-Fast-RCNN-Faster-RCNN/"}]},{"title":"深度学习中的优化","date":"2019-04-23T15:06:14.000Z","path":"2019/04/23/深度学习中的优化/","text":"1.前言针对深度学习中不同的优化问题和应用场景，研究人员提出了多种不同的求解算法。在众多优化算法中，有几个经典常用的优化值得被牢记，主要是几个一阶的梯度的算法，包括GD，SGD，Momentum，AdaGrad，RMSProp，Adam。其中SGD，Momentum是需要事先人工设置学习率，而AdaGrad，RMSProp，Adam是自动调节学习率的。 2.GD(gradient descent)BGD在训练中，每次迭代需要使用训练集中的所有样本，也就是说利用现有参数对训练集中的所有样本的输入生成一个估计$\\hat{y}_i$，然后根据实际的$y_i$作差求出平均值并以此来更新参数。 2.1具体实现需要：学习速率$\\epsilon$，初始参数$\\theta$迭代过程： 提取训练集中所有特征${x_1,…,x_n}$，以及对应的标签$y_i$ 计算梯度和误差并更新参数：​ $\\hat{g}\\leftarrow+\\frac{1}{n}\\nabla_{\\theta}\\sum_{i}L(f(x_i;\\theta),y_i)$​ $\\theta\\leftarrow\\theta-\\epsilon\\hat{g}$2.2优点由于每一步迭代使用了全部样本，因此当损失函数收敛过程比较稳定2.3缺点也是由于每次迭代使用所有样本，因此随着数据集的增大，运行速度会越来越慢 3.BGD(batch gradient descent)批量梯度下降，即每次迭代随机抽取一批样本（全体样本的一个子集）来更新参数 3.1具体实现需要：学习速率$\\epsilon$，初始参数$\\theta$每次迭代过程： 从训练集中随机抽取一批样本${x_1,…,x_m}$(其中m&lt;n),以及对应的标签$y_i$ 计算损失的梯度并跟新参数： $\\hat{g}\\leftarrow+\\frac{1}{m}\\nabla_{\\theta}\\sum_{i}L(f(x_i;\\theta),y_i)$ $\\theta\\leftarrow\\theta-\\epsilon\\hat{g}$3.2优点由于每次迭代不是使用全样本，因此训练速度快，对于很大的数据集也能以较快的速度收敛3.3缺点由于每次是随机抽取一小批样本，因此损失无法表征全局的损失趋势，计算得到的梯度也有误差补充一句当BGD每次仅抽取的一小批样本仅含有一个时，此时就是随机梯度下降（SGD），SGD的优点是计算速度快，缺点是损失函数曲线可能不稳定，需要更多个epoch才能收敛 4.MomentumSGD存在的问题是，当每次迭代计算梯度的时候会含有很大噪声，而Momentum方法可以较好的缓解这个问题，尤其是在面对小而连续的梯度但含有很多噪声的时候，可以更好地加快收敛。Momentum借鉴了物理学动量的概念，即前几次的梯度也会参与到本次迭代。为了表示动量，引入一个新的变量$\\nu$,$\\nu$是历史梯度的累加和，但是每次都会有一定衰减 4.1 具体实现需要：学习速率$\\epsilon$，初始参数$\\theta$，初始速率$nu$，动量衰减参数$\\alpha$迭代过程： 从训练集中随机抽取一批容量为m的样本${x_1,…,x_m}$，以及对应的标签$y_i$ 计算损失和梯度，并更新速度$nu$，和参数$\\theta$ $\\hat{g}\\leftarrow+\\frac{1}{m}\\nabla_{\\theta}\\sum_{i}L(f(x_i;\\theta),y_i)$ $\\nu\\leftarrow\\alpha\\nu-\\epsilon\\hat{g}$ $\\theta\\leftarrow\\theta-\\epsilon\\hat{g}$其中参数$\\alpha$表示每回合速率v的衰减程度.同时也可以推断得到,如果每次迭代得到的梯度都是g,那么最后得到的$\\nu$的稳定值为$\\frac{\\epsilon||g||}{1-\\alpha}$4.2特点前后梯度一致的时候能够加速学习前后梯度不一致的时候能够抑制震荡，越过局部极小值 5 AdaGradAdaGrad是一种可以自动改变学习速率的优化算法，只需设定一个全局学习速率$\\epsilon$，每次迭代使用的学习速率是与历史梯度有关 5.1具体实现需要：全局学习速率$\\epsilon$,初始参数$\\theta$，一个很小的大于0的数值稳定量$\\delta$中间变量：梯度累计量r迭代过程： 从训练集中随机抽取一批容量为m的样本${x_1,…,x_m}$，以及对应的标签$y_i$ 计算损失和梯度，更新r，在根据r和梯度更新参数 $\\hat{g}\\leftarrow+\\frac{1}{m}\\nabla_{\\theta}\\sum_{i}L(f(x_i;\\theta),y_i)$ $r\\leftarrow r+\\hat{g}\\bigotimes\\hat{g}$ $\\Delta\\theta=-\\frac{\\epsilon}{\\delta+\\sqrt{r}}\\bigotimes\\hat{g}$ $\\theta\\leftarrow\\theta+\\Delta\\theta$5.2优点能够实现学习速率的自动更改，如果本次梯度大，那么学习速率衰减的就快一些，如果本次梯度小，那么学习速率就衰减的慢一下。5.3缺点依旧需要设置一个全局的学习率$\\epsilon$经验表明，在普通算法中或许效果不错，但是在深度学习中，深度过深时会造成训练提前结束 6.RMSPropRMSProp通过引入一个衰减系数，让r每次都以一定的比例衰减，类似于Momentum中的做法 6.1具体实现需要：全局学习速率$\\epsilon$，初始参数$\\theta$,一个很小的大于0的数值稳定量$\\delta$，衰减速率$\\rho$迭代过程： 从训练集中随机抽取一批容量为m的样本${x_1,…,x_m}$，以及对应的标签$y_i$ 计算损失和梯度，更新r，再根据r和梯度更新模型参数 $\\hat{g}\\leftarrow+\\frac{1}{m}\\nabla_{\\theta}\\sum_{i}L(f(x_i;\\theta),y_i)$ $r\\leftarrow\\rho r+(1-\\rho)\\hat{g}\\bigotimes\\hat{g}$ $\\Delta\\theta=-frac{\\epsilon}{\\delta+\\sqrt{r}}\\bigotimes\\hat{g}$ $\\theta\\leftarrow\\theta+\\Delta\\theta$6.2优点相比于AdaGrad，这种方法更好的解决了深度学习中过早的结束学习的问题适合处理非平稳目标，对RNN效果很好6.3缺点引入的新的超参，衰减系数$\\rho$依然依赖于全局学习速率 7 Adam(Adaptive Moment Esitimation)Adam本质上是带有动量项的RMSProp，它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。Adam的优点主要在于经过偏置矫正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。 7.1具体实现需要：步进值$\\epsilon$，初始参数$\\theta$，数值稳定值$\\delta$，一阶动量衰减系数$\\rho_1$，二阶动量衰减系数$\\rho_2$其中几个取值一般为：$\\delta=10^{-8}, \\rho_1=0.9, \\rho_2=0.999$中间变量：一阶动量s，二阶动量r，都初始化为0迭代过程： 从训练集中随机抽取一批容量为m的样本${x_1,…,x_m}$，以及对应的标签$y_i$ 计算损失和梯度，更新r和s，在根据r和s以及梯度更新模型参数 $g\\leftarrow+\\frac{1}{m}\\nabla_{\\theta}\\sum_{i}L(f(x_i;\\theta),y_i)$ $s\\leftarrow\\rho_1 s + (1-\\rho_1)g$ $r\\leftarrow\\rho_2 r + (1-\\rho_2)g\\bigotimes g$ $\\hat{s}\\leftarrow\\frac{s}{1-\\rho_1}$ $\\hat{r}\\leftarrow\\frac{r}{1-\\rho_2}$ $\\Delta\\theta=-\\epsilon \\frac{\\hat{s}}{\\sqrt{\\hat{r}}+\\delta}$ $\\theta\\leftarrow\\theta+\\Delta\\theta$7.2 优点适用于绝大多数情况7.3 缺点复杂","tags":[{"name":"optimizer deeplearning","slug":"optimizer-deeplearning","permalink":"http://yoursite.com/tags/optimizer-deeplearning/"}]},{"title":"理解各种各样的CNN架构","date":"2019-04-15T13:27:37.000Z","path":"2019/04/15/理解各种各样的CNN架构/","text":"ResNet-Alexnet-VGG-Inception:理解各种各样的CNN架构本文翻译自ResNet、AlexNet、VGG、Inception：Understanding various architecture of Convelutional Neural Network ResNet、AlexNet、VGG、Inception：Understanding various architecture of Convelutional Neural Network 原作者保留版权。 卷积神经网络（CNN）在视觉识别任务上的表现令人惊奇。好的CNN网络是带有上百万参数和寻多隐藏层的“庞然怪物”。事实上，一个不好的经验规则是：网络越深，效果越好。要打破这种认知 AlexNet、VGG、Inception和ResNet都是最近一些流行的CNN网络。 为什么这些网络表现如此只好？它们又是如何设计出来的？为什么他们设计成那样的结构？回答这些问题并不简单，但是这里我们试着去探讨上面的几个问题。 网络结构设计是一个复杂的过程，需要花很多时间 为什么CNN模型战胜了传统计算机视觉方法？图像分类指的是：给定一个图片，将其分类成预定义好的几个类别之一。图像分类的传统流程设计两个模块：特征提取和分类 特征提取指的是从原始像素提取更高级的特征，这些特征能够捕捉到类别之间的区别。这种特征提取的方式是使用无监督方式，从像素点中提取信息时，没有使用图像的类别标。 常用的传统特征包括GIST、HOG、SIFT、LBP等。特征提取后，使用图像的这些特征与其对应的类别标签训练一个分类模型。常用的分类模型有SVM、LR、随机森林及决策树等。 上面流程的一大问题是： 特征提取不能根据图像及其标签进行调整。如果选择的特征缺乏一定的代表性来区分各个类别，模型的准确度就会大打折扣，而无论采取什么样的分类策略。 采用传统的流程，目前的一个比较好的方法是使用多种特征提取器，然后组合他们得到一种更好的特征（组合特征）。 但是这需要很多启发式规则和人力来根据领域的不同来调整参数，使得达到一个很好的准确度，这里说的是要接近人类的水平。 这也就是说，为什么采用传统的计算机视觉技术需要花费很多年时间才能打造出一个好的计算机视觉系统（例如：OCR、人脸验证、图像识别、物体检测），这些系统在实际应用中可以处理各种数据。 有一次，我们用了6周时间为一家公司打造了一个CNN模型，其效果更好，如果采用传统的计算机视觉技术要达到同样效果则要花费一年时间。 传统流程的另一个问题是： 它与人类识别学习物体的过程是完全不一样的。人自出生之初，一个孩子就可以感知周围环境，随着他的成长，他接触的数据更多，从而学会了识别物体。 这是深度学习背后的哲学，其中并没有建立硬编码的特征提取器。它将特征提取和分类两个模块集成为一个系统，通过识别图像的特征来进行提取并基于有标签的数据进行分类。 这样的集成系统就是多层感知机。即有多层神经元密集连接而成的神经网络。 一个经典的深度网络包含很多参数，由于缺乏足够的训练样本，基本不可能训练处一个不过拟合的模型。 但是，对于CNN模型，从头开始训练一个网络时，你可以使用一个很大的数据集，比如ImageNet。这背后的原因是CNN模型的两个特点：神经元间的权重共享和卷积层之间的稀疏连接。 这可以从下图看出，在卷积层，某一个层的神经元只是和输入层的神经元局部连接，而且卷积核的参数时在整个2-D特征图上共享的。 为了理解CNN背后的设计哲学，你可能会问：其目标是什么？（1）准确度 如果你在搭建一个智能系统，最重要的当然是要尽可能的准确。公平的来说，准确度不仅取决于网络，也取决于训练样本的数量。因此，CNN模型一般在一个标准数据集ImageNet上做对比。 ImageNet项目仍然在继续改进，目前已经有包含21,841类的14,197,122个图片。自从2010年，每年都会举行ImageNet图像识别竞赛，比赛会提供从ImageNet数据集中抽取属于1000类的120万中图片。 每个网络架构都是在这120W张图片上测试其在1000分类上的准确度。 （2）计算量 大部分CNN模型都需要很大的内存和计算量，特别是在训练过程中。因此，计算量会成为一个重要的关注点。同样的，如果你想部署在移动端，训练得到的最终模型大小也需要特别考虑。 你可以想象到，为了得到更好的准确度，你需要一个计算更密集的网络，因此，准确度和计算量需要折中。 除了上面两个因素，还有其他需要考虑的因素，比如训练的容易度，模型的泛化能力等。下面按照提出时间，介绍一些流行的CNN架构，可以看到他们的准确度越来越高。 AlexNetAlexNet AlexNet是一个较早应用于ImageNet上的深度网络，其准确度相比传统方法有一个很大的提升。它首先是5个卷积层，然后紧跟着是3个全连接层，如下图所示： Alex Krizhevs提出的AlexNet首次采用了Relu激活函数，而不像传统神经网络早期所采用的Tanh或Sigmoid激活函数，ReLU数学表达式为：$f(x)=max(0,x)$ ReLU相比Sigmoid的优势是其训练速度更快，因为Sigmoid的导数在稳定区会非常小，从而其权重基本不再更新。这就是梯度消失问题。因此，AlexNet在卷积层和全连接层后面使用了ReLu激活函数。 AlexNet的另一个特点是其通过在每个全连接层后面加了Dropout层减少了模型的过拟合问题。Dropout层以一定的概率随机地关闭当前层中神经元激活值，如下图所示： 为什么Dropout有效？ Dropout背后的理念和集成模型很相似。在Dropout层，不同的神经元组合被关闭，这代表了一种不同的结构，所有这些不同的结构都是与每个子集的权值并行训练的，权值之和为1. 如果Dropout层有n个神经元，那么会形成$2^n$个不同的子结构，在预测时，相当于集成这些模型并取均值，这种结构化的模型正则化技术有利于避免过拟合。 Dropout有效的另一个观点是：由于神经元是随机选择的，所以可以减少神经元之间的相互依赖，从而确保提取出相互独立的重要特征。 AlexNet代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport torchvisionimport torchvision.transforms as transforms# import torchvision.datasets as datasetsimport osimport randomimport numpy as npclass AlexNet(nn.Module): def __init__(self): #init函数定义的是网络的架构、关键的网络模块、模组 super(AlexNet,self).__init__() self.feature_block=nn.Sequential( # Conv2d位置参数：in_channels，out_channels nn.Conv2d(3,64,kernel_size=11,stride=4,padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3,stride=2), nn.Conv2d(64,192,kernel_size=5,padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3,stride=2), nn.Conv2d(192,384,kernel_size=3,padding=1), nn.ReLU(inplace=True), nn.Conv2d(384,256,kernel_size=3,padding=1), nn.ReLU(inplace=True), nn.Conv2d(256,256,kernel_size=3,padding=1), nn.ReLU(inplace=True) ) #5个连续的卷积层 self.avgpool=nn.AdaptiveAvgPool2d((6,6)) self.class_block=nn.Sequential( nn.Dropout() nn.Linear(256*6*6,4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096,4096), nn.ReLU(inplace=True), nn.Linear(4096,10) ) def forward(self,x): x=self.feature_block(x) x=self.avgpool(x) x=x.view(x.size[0],256*6*6) x=self.class_block(x) return VGG-16VGG-16 VGG-16是牛津大学VGG组提出的。VGG16相比AlexNet的一个改进是采用连续的几个3*3卷积核代替AlexNet中较大的卷积核（11*11,5*5）。 对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。 比如，3个步长为1的3×3卷积核连续作用在一个大小为7的感受野，其参数总量为3×(3^3×C^2),如果直接使用7×7卷积核，其参数总量为7^7×C^2,这里的C值得是出入和输出的通道数。 而且3×3卷积核有利于更好地保持图像性质。VGG网络的架构如下所表示： 可以看到VGG使用了一种块结构，多次重复使用同一大小的卷积核来提取更复杂和更具有表达性的特征。这种块（blocks/modules）在VGG之后被广泛采用。 VGG卷积层之后是3个全连接层。网络的通道数从较小的64开始，然后每经过一个downsample或者池化层成倍地增加，当然特征图大小成倍地减小。最终其在ImageNet上的Top-5准确度为92.3% VGG代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class VGGBlock(nn.Module): def __init__(self,in_channels,out_channels,batch_norm): #在后来，改良后的VGG网络增加了BatchNorm super(VGGBlock,self).__init__() stack=[] stack.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1)) if batch_norm: stack.append(nn.BatchBorm2d(out_channels)) stack.append(nn.ReLU(inplace=True)) self.model_block=nn.Sequential(*stack) def forward(self,x): return self.model_block(x) class VGG11(nn.Module): def __init__(self,block,pool,batch_norm): self.feature_block=nn.Sequential( block(3,64,batch_norm), #32*32个 pool(kernel_size=2,stride=2), #16*16 block(64,128,batch_norm), pool(kernel_size=2,stride=2) #8*8 block(126,256,batch_norm), block(256,256,batch_norm), pool(kernel_size=2,stride=2), #4*4 block(256,512,batch_norm), block(512,512,batch_norm), pool(kernel_size=2,stride=2), #2*2 block(512,512,batch_norm), block(512,512,batch_borm), pool(kernel_size=2,stride=2), #1*1 ) self.classifier=nn.Linear(512,10) def forward(self,x): x=self.feature_block(x) x=x.view(x.size[0],-1) x=self.classifier(x) return class VGG16(nn.Module): def __init__(self,block,pool,batch_norm): super(VGG16,self).__init__() self.feature_block=nn.Sequential( block(3,64,batch_norm), block(64,64,batch_norm), pool(kernel_size=2,stride=2), block(64,128,batch_norm), block(128,128,batch_norm), pool(kernel_size=2,stride=2), block(128,256,batch_norm), block(256,256,batch_norm), block(256,256,batch_norm), pool(kernel_size=2,stride=2), block(256,512,batch_norm), block(512,512,batch_norm), block(512,512,batch_norm), pool(kernel_size=2,stride=2), block(512,512,batch_norm), block(512,512,batch_norm), block(512,512,batch_norm), pool(kernel_size=2,stride=2), ) self.classifier=nn.Linear(512,10) def forward(self,x): x=self.feature_block(x) x=x.view(x.size[0],-1) x=self.classifier(x) return x GoogLeNet/Inception尽管VGG可以在ImageNet上表现很好，但是将其部署在一个适度大小的GPU上是困难的，因为需要VGG在内存和时间上的计算要求都很高。由于卷积层的通道数过大，VGG并不高效。 比如，在一个3×3的卷积核，如果其输入和输出的通道数均为512，那么需要的计算量为9×512×512. 在卷积操作中，输出特征图上某一个位置，其是与所有的输入特征图是相连的，这是一种密集连接结构。 GoogLeNet 基于这样的理念：在深度网络中大部分的激活值是不必要的（为0），或者由于相关性是冗余。因此，最高效的深度网络架构应该是激活值之间是稀疏连接的，这就意味着512个输出特征图是没必要与所有的512输入特征图相连。 存在一些技术可以对网络进行剪枝来得到稀疏权重或者连接。但是稀疏卷积核的乘法在BLAS和CuBlas中并没有优化，这反而造成稀疏连接结构比密集结构更慢。 据此，GoogLeNet设计了一种称为inception的模块，这个模块使用密集结构来近似一个稀疏的CNN，如下图所示。 前面说过，只有很少一部分神经元是真正有效的，所以一种特定大小的卷积核数量设置地非常小。同时，GoogLeNet使用了不同大小的卷积核来抓取不同大小的感受野。 Inception模块的另一个特点是使用了一种瓶颈层（事实上就是1×1卷积）来降低计算量： 这里假定Inception模块的输入为192通道，它使用128个3×3卷积核和32个5×5卷积核。5×5卷积的计算量为25×32×192，但是随着网络变深，网络的通道数和卷积核数会增加，此时计算量就暴涨了。为了避免这个问题，在使用较大卷积核之前，先去降低通道数。 所以，Inception模块首先送入只有16个1×1层卷积层，然后再送给5×5卷积层。这样整体计算量会减少为16×192+25×32×16。这种设计允许网络可以使用更大的通道数。（译者注：之所以称1×1卷集层为瓶颈层，可以想象一下一个1×1卷积层拥有最少的通道数，这在Inception模块就像一个瓶子的最窄处。） GoogLeNet的另一个特殊设计是最后的卷积层后使用全局均值池化层替换了全连接层，所谓全局池化就是在整个2D特征图上取均值。 这大大减少了模型的总参数量。要知道在AlexNet中，全连接层参数占到整个网络总参数的90%，使用一个更大更深的网络使GoogLeNet移除全连接层之后还不影响准确度。其在ImageNet上的top-5准确度为93.3%，但是速度还比VGG快。 GoogLeNet代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Inception(nn.Module): def __init__(self,in_planes,n1x1,n3x3red,n3x3,n5x5red,n5x5,pool_planes): super(Inception,self).__init__() self.b1=nn.Sequential( nn.Conv2d(in_planes,n1x1,kernel_size=1), nn.BatchNorm2d(in_planes), nn.ReLU(True), ) self.b2=nn.Sequential( nn.Conv2d(in_planes,n3x3red,kernel_size=1), nn.BatchNorm2d(n3x3red), nn.ReLU(True), nn.Conv2d(n3x3red,n3x3,kernel_size=3,padding=1), nn.BatchNorm2d(n3x3), nn.ReLU(True), ) self.b3=nn.Sequential( nn.Conv2d(in_planes,n5x5red,kernel_size=1), nn.BatchNorm2d(n5x5red), nn.ReLU(True), nn.Conv2d(n5x5red,n5x5,kernel_size=5,padding=2), nn.BatchNorm2d(n5x5), nn.ReLU(True), ) self.b4=nn.Sequential( nn.MaxPool2d(3,stride=1,padding=1), nn.Conv2d(in_planes,pool_planes,kernel_size=1), nn.BatchNorm2d(pool_planes), nn.ReLU(True), ) def forward(self,x): x1=self.b1(x) x2=self.b2(x) x3=self.b3(x) x4=self.b4(x) # concat 4层输入到一起 return torch.cat([x1,x2,x3,x4],1) class GoogLeNet(nn.Module): def __init__(self): super(GoogLeNet,self).__init__() self.feature_block=nn.Sequential( nn.Conv2d(1,192,kernel_size=3,padding=1), nn.BatchNorm2d(192), nn.ReLU(True), ) self.a3=Inception(192,64,96,128,16,32,32) self.b3=Inception(256,128,128,192,32,96,64) self.maxpool=nn.MaxPool2d(3,stride=2,padding=1) self.a4=Inception(480,192,96,208,16,48,64) self.b4=Inception(512,160,112,224,24,64,64) self.c4=Inception(512,128,128,256,24,64,64) self.d4=Inception(512,112,144,288,32,64,64) self.e4=Inception(528,256,160,320,32,128,128) self.a5=Inception(832,256,160,320,32,128,128) self.b5=Inception(832,384,192,384,48,128,128) self.avgpool=nn.AvgPool2d(8,stride=1) self.linear=nn.Linear(1024,10) def forward(self,x): out=self.feature_block(x) out=self.a3(out) out=self.b3(out) out=self.maxpool(out) out=self.a4(out) out=self.b4(out) out=self.c4(out) out=self.d4(out) out=self.e4(out) out=self.maxpool(out) out=self.a5(out) out=self.b5(out) out=self.avgpool(out) out=out.view(out.size(0),-1) out=self.linear(out) return out ResNet从前面可以看到，随着网络深度增加，网络的准确度应该同步增加，当然要注意过拟合问题。但网络深度增加的一个问题在于这些增加的层是参数更新的信号，因为梯度是从后向前传播的，增加网络深度后，比较靠前的层的梯度会很小。 这意味着这些层基本上学习停滞了，这就是梯度消失问题。深度网络的第二个问题在于训练，当网络更深时，意味着参数空间更大，优化问题变得更难，因此简单的去增加网络深度反而出现更高的训练误差。 残差网络【ResNet】 设计一种残差模块，让我们可以训练更深的网络 为什么残差容易训练？ $y_l=h(x_l)+F(x_l,W_l)$ $x_{l+1}=f(y_l)$ $h(x_l)=x_l$ $x_L=x_l+\\sum_{i=l}^{L-1}F(x_i,W_i)$ 其中：$F$是残差函数 || $h$是恒等变换 || $x_L$是融合后的函数 || $f$是激活函数 $\\cfrac{\\partial loss}{\\partial x_l}=\\cfrac{\\partial loss}{\\partial x_L}·\\cfrac{\\partial x_L}{\\partial x_l}=\\cfrac{\\partial loss}{\\partial x_L}·\\left( 1 + \\cfrac{\\partial}{\\partial x_L}\\sum_{i=l}^{L-1}F(x_i,W_i)\\right)$ 深度网络的训练问题称之为退化问题，残差单元可以解决退化问题的背后逻辑在于此：想象一个网络A，其训练误差为x。现在通过A上面堆积更多的层来构建网络B，这些新增的层什么也不做，仅仅复制前面A的输出，这些新增层称之为C。 这意味着，网络B应该和A的训练误差一样，那么训练网络B其训练误差应该不会差于A。但是实际上却是更差，唯一的原因是，让增加的层C学习恒等映射并不容易。为了解决这个退化问题，残差模块在输入和输出特征之间建立了一个直接连接，这样新增的层C仅仅需要在原来的输入层基础上学习新特征，即学习残差，会比较容易。 与GoogLeNet类似，ResNet也在最后使用了全局均值池化层。利用残差模块，可以训练152层的残差网络，其准确度比VGG和GoogLeNet要高，但是计算效率也比VGG高，152层的ResNet其Top-5准确度为95.51% ResNet主要使用3×3卷积，这与VGG类似，在VGG基础上，短路连接插入形成残差网络。如图所示： 残差网络实验结果表明：34层的普通网络比18层网络训练误差还大，这就是前面所说的退化问题。但是34层的残差网络比18层残差网络训练误差要好。 ResNet代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class ResNetBlock(nn.Module): def __init__(self,in_channels,out_channels,stride): super(ResNetBlock,self).__init__() self.conv1=nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False) self.bn1=nn.BatchNorm2d(out_channels) self.conv2=nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False) self.bn2=nn.BatchNorm2d(out_channels) self.downsample=nn.Sequential() if stride!=1 or in_channels!=out_channels: self.downsample=nn.Sequential( nn.Conv2d(in_channels,out_channels,kernel_size=1,strid=stride,bias=False), nn.BatchNorm2d(out_channels) ) def forward(self,x): out=F.relu(self.bn1(self.conv1(x))) out=self.bn2(self.conv2(out)) out+=self.downsample(x) #ResNet的add操作，其实是张量的加和 out=F.relu(out) return out class ResNetLayer(nn.Module): def __init__(self,block,n_blocks,in_channels,out_channels,stride): super(ResNetLayer,self).__init__() self.modules=[] self.modules.append(block(in_channels,out_channels,stride)) for _ in range(n_blocks-1): self.modules.append(block(out_channels,out_channels,1)) self.blocks=nn.Sequential(*self.modules) def forward(self,x): return self.blocks(x) class ResNet18(nn.Module): def __init__(self,layer,block): super(ResNet18,self).__init__() n_blocks=[2,2,2,2] self.conv1=nn.Conv2d(3,64,kernel_size=2,stride=1,padding=1,bias=False) self.bn1=nn.BatchNorm2d(64) self.rb1=layer(block,n_blocks[0],64,64,1) self.rb2=layer(block,n_blocks[1],64,128,2) self.rb3=layer(block,n_blocks[2],128,256,2) self.rb4=layer(block,n_blocks[3],256,512,2) self.fc=nn.Linear(512,10) def forward(self,x): out=F.relu(self.bn1(self.conv1(x))) out=self.rb1(out) out=self.rb2(out) out=self.rb3(out) out=self.rb4(out) out=F.avg_pool2d(out,4) out=out.view(out.shape[0],-1) out=self.fc(out) return out DenseNetDenseNet是一种具有密集连接的卷积神经网络，即：任何两层之间都有直接的连接。也就是说，网络每一层的输入都是对前面所有层输出的并集，而该层所学习的特征图也会被直接传给其后所有层作为输入。这种密集连接，通过将feature在channel上的连接来实现特征重用（feature reuse），这让DenseNet在参数和计算成本更少的情形下实现比ResNet更优的性能，DenseNet也因此斩获CVPR2017的最佳论文奖。 章节目录 密集连接机制 网络组成架构 DenseBlock和Transition的细节 DenseNet的优点 FC-DenseNet语义分割 密集连接机制即相互连接所有的层，具体来说就是每个层都会接受前面所有层作为其额外的输入，在DenseNet中，每个层都会与前面所有层在Channel维度上连接（conact）在一起，并作为下一层的输入。对于一个L层网络，DenseNet共包含L(L+1)/2个连接。DenseNet是直接concat来自不同层的特征图来实现特征重用。 网络组成架构由于密集连接的时候要求特征图大小是一致的，为了随着网络深度的加深，特征图大小也降低，也就是使用pooling，使用DenseBlock和Transition两种模块来组合。DenseBlock模块里面层与层之间采用密集连接方式，Transition连接两个相邻的DenseBlock，使用Pooling降低分辨率。看图： DenseBlock和Transition的细节 非线性组合： DenseBlock中非线性组合函数，比如：BN+ReLU+3x3 Conv结构，而且各个层的特征图大小是一致的，这样才能保证channel维度上的concat。 增长率（Growth Rate） 由于网络中每一层都直接与其它层相连接，实现特征的重复利用，因此为了降低冗余性，使用了一个超参K，用于控制每一层输出的feature maps厚度，那一般情况下使用较小的K（比如12），目睹是为了把网络的每一层设计的特别【窄】，即只学习非常少的特征图（最极端的情况是每一层只学习一个特征图）。假定输入层的特征图的channel数为3，那么L层输入的channel数为3+K(L-1),因此随着层数增加，尽管k设定的较小，DenseBlock的输入会非常多，不过这是由于特征重用造成的，每个层仅有K个特征是自己独有的，使用K个卷积核对（x0,x1,x2,x3）组成的特征图进行非线性变换得到通道数为K的x4,再通过x4和前面每个阶段的特征图拼接起来得到（x0,x1,x2,x3,x4） bottleneck层 虽然k使用了较小的值，但是通过多个层不断的密集连接，最终特征图的通道数还是会比较大而造成网络计算量增大。因此在非线性变换的时候引入了1x1的卷积来进行降维，引入1x1卷积之后的非线性变换变成了BN+ReLU+1x1Conv+BN+ReLU+3x3Conv，称之为DenseNet-B结构，看图： Transition层： Transition层也是非线性变换函数组成的模块，组合方式为：BN+ReLU+1x1Conv+2x2Pooling，既然是非线性变换组合，在这个组合中加入pooling就可以起到降低特征图大小的作用，那么它可以通过控制输入的卷积核个数，起到进一步压缩特征图的作用。假设一个DenseBlock中包含m个特征图，那么我们使其输出连接的transition layer层生成$\\theta m$个输出特征图。当这里的$\\theta$取值为(0,1]时，起到压缩的作用，因此可以叫做压缩系数，当$\\theta =1$时，transition layer将保留原特征feature维度不变。 DenseNet优点(1)省参数，在ImageNet分类数据集上达到相同的准确率，在DenseNet上所需参数量不到ResNet一半。 (2)省计算，达到与ResNet相当的精度，DenseNet所需计算量也只有ResNet的一半左右。 (3)抗过拟合，对于DenseNet抗过拟合的原因有一个比较直观的解释：神经网络每一层提取特征都相当于对输入数据的一个非线性变换，随着深度的增加，变换的复杂度也逐渐增加(更多非线性函数的组合)。相比于一般神经网络直接依赖于网络最后一层（复杂度最高）的特征，DenseNet可以综合利用前层复杂度低的特征，因而更容易得到一个光滑的具有更好泛化性能的决策函数。 (4)支持特征重用，强化特征传播，有效解决梯度消失问题。 FC-DenseNet语义分割参考 由上图可以看出，全卷机DenseNet使用DenseNet作为它的基础编码器，并且也以类似于U-Net的方式，在每一层级上将编码器和解码器进行拼接。在解码阶段，将卷及操作替换为dense模块，并由transition up模块完成升采样，transition up模块使用的转置卷积升采样以前的特征图，然后将升采样后的特征图连接到来自下采样过程中的dense模块的跨层连接。需要注意的是，为了解决特征图数目的线性增长问题，dense模块的输入并不连接到它的输出，转置卷积仅对最后一个dense block的特征图使用。因为最后一个dense模块包含了前面虽有部分分辨率dense模块信息之和。同时引入跳层解决之前dense block特征损失的问题。网络结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import mathclass Bottleneck(nn.Module): def __init__(self,in_planes,growth_rate): super(Bottleneck,self).__init__() self.bn1=nn.BatchNorm2d(in_planes) self.conv1=nn.Conv2d(in_planes,4*growth_rate,kernel_size=1,bias=False) self.bn2=nn.BatchNorm2d(4*growth_rate) self.conv2=nn.Conv2d(4*growth_rate,growth_rate,kernel_size=3,padding=1,bias=False) def forward(self,x): out=self.conv1(F.relu(self.bn1(x)))#pre-activation out=self.conv2(F.relu(self.bn2(out))) out=torch.cat([out,x],1) return outclass Transition(nn.Module): def __init__(self,in_planes,out_planes): super(Transition,self).__init__() self.bn=nn.BatchNorm2d(in_planes) self.conv=nn.Conv2d(in_planes,out_planes,kernel_size=1,bias=False) def forward(self,x): out=self.conv(F.relu(self.bn(x))) out=F.avg_pool2d(out,2) return outclass DenseNet(nn.Module): def __init__(self,block,nblocks,growth_rate=12,reduction=0.5,num_classes=10): super(DenseNet,self).__init__() self.growth_rate=growth_rate num_planes=2*growth_rate #32 #最初的感知层 self.conv1=nn.Conv2d(3,num_planes,kernel_size=3,padding=1,bias=False) #第一个DenseBlock self.dense1=self._make_dense_layers(block,num_planes,nblocks[0]) num_planes+=nblocks[0]*growth_rate out_planes=int(math.floor(num_planes*reduction)) self.trans1=Transition(num_planes,out_planes) num_planes=out_planes #第二个DenseBlock self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1]) num_planes += nblocks[1]*growth_rate#计算如果不压缩的话的输出 out_planes = int(math.floor(num_planes*reduction)) self.trans2 = Transition(num_planes, out_planes) num_planes = out_planes #第三个DenseBlock self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2]) num_planes += nblocks[2]*growth_rate out_planes = int(math.floor(num_planes*reduction)) self.trans3 = Transition(num_planes, out_planes) num_planes = out_planes #第四个DenseBlock self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3]) num_planes += nblocks[3]*growth_rate #分类层 self.bn=nn.BatchNorm2d(num_planes) self.linear=nn.Linear(num_planes,num_classes) def _make_dense_layers(self,block,in_planes,nblock): #block:bottleneck #nblock代表构建denseblock中有多少bottleneck层 layers=[] for i in range(nblock): layers.append(block(in_planes,self.growth_rate)) in_planes+=self.growth_rate return nn.Sequential(*layers) def forward(self,x): out=self.conv1(x) out=self.trans1(self.dense1(out)) out = self.trans2(self.dense2(out)) out = self.trans3(self.dense3(out)) out = self.dense4(out) out=F.avg_pool2d(F.relu(self.bn(out)),4) out=out.view(out.size(0),-1) out=self.linear(out) return outdef DenseNet121(): return DenseNet(Bottleneck,[6,12,24,16],growth_rate=32)","tags":[{"name":"CNN arch deeplearning","slug":"CNN-arch-deeplearning","permalink":"http://yoursite.com/tags/CNN-arch-deeplearning/"}]}]